---
title: "Statistical Quality Control Book - Montgomery"
author: "Jeff Li"
date: "`r Sys.Date()`"
output: 
  html_document: 
    toc: true
    toc_depth: 3
    toc_float: true
---

"I maintained my edge by always being a student; you will always have something new to learn". - Jackie Joyner Kersee



## (I) Load Required Libraries
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(pdftools)
```



# 6. control Charts for Variables 

The $\bar{x}$ and R control charts are widely used to monitor the mean and variability of variables. 


## 6.1 Introduction

When dealing with a quality characteristic that is a variable, it is usually necessay to monitor both the mean and variabilit. 

```{r}
# Define upper- and lower- specification limits
upper_specification_limit <- 13
lower_specification_limit <- 7

# simulated data 
set.seed(123)
prod_x <- data.frame(x = rnorm(n = 10000, mean = 10, sd = 1))

# plot
prod_x %>%
  ggplot(aes(x = x)) +
  geom_histogram(bins = 100) + 
  geom_histogram(aes(x = rnorm(n = 10000, mean = 12, sd = 1), alpha = 0.7), bins = 100) +
   geom_histogram(aes(x = rnorm(n = 10000, mean = 10, sd = 2), alpha = 0.7), bins = 100) +
  geom_vline(xintercept = c(upper_specification_limit, lower_specification_limit, 10, 12))

```


## 6.2 Control Charts for X_bar and R 

$\bar{x}$


```{r}
sim <- NULL

for (i in seq(1:1e9)) {
  sim[i] = diff(range(rnorm(n = 5), mean = 0, sd = 1))
}

mean(sim)

```


# 8. Process and Measurement System Capability Analysis

## 8.1 Introcution 

* **Natural tolerance limits of the process**: 
$$UNTL = \mu + 3\sigma$$
$$LNTL = \mu - 3\sigma$$

For a normal distribution, the NTL include 99.73% of the variable, or in another word, only 0.27% of the process output will fall outside the natural tolerarnce limits. 

Process capability analysis is a vital part of an overal quality-improvement program. The major uses include following: 

* 1. Predicting how well the process will hold the tolerances

* 2. Assisting product developers/designers in selecting or modifying a process

* 3. Assisting in establishing an interval between sampling for process monitoring

* 4. Specifying performance requirement for new equipment

* 5. Reducing the variability in a process 

Three primary techniquies used in process capability analysis include: *histograms/probability plots*, *control charts*, and *designed experiments*. 

## 8.2 Process Capability Analysis Using a Histogram or a Probability Plot

### 8.2.1 Using the Histogram

```{r}
dir("data/")
# (a) read the data
bursting_strengths_100_glass_raw <- readxl::read_excel("data/ch08.xlsx", 
                                                   sheet = "table8_1") 

# (b) clean and reformat data
bursting_strengths_100_glass <- str_split(bursting_strengths_100_glass_raw$values, pattern = " " ) %>%
  map(as.numeric) %>%
  unlist() %>%
  as.data.frame() %>%
  select(bursting_strenths_psi = '.')
 
# mean and sd
bursting_strengths_100_glass %>%
  summarise(mean = mean(bursting_strenths_psi), 
            sd = sd(bursting_strenths_psi))

bursting_strengths_100_glass %>%
  ggplot(aes(x = bursting_strenths_psi)) +
  geom_histogram(bins = 9)
```

### 8.2.2 Probability Plotting

As an alternative to the histogram, probability plotting can be used to determine the shape, center, and spread of the distribution. Compared with the histogram, dividing the range of the variable into class intervals is unnecessary. 

```{r}
bursting_strengths_100_glass %>%
  ggplot(aes(sample = bursting_strenths_psi)) +
  stat_qq() + 
  stat_qq_line()
```

For the normal distribution, the standard deviation can be estimated as the difference between the eighty-fourth adn the fiftieth percentiles. 

$$\hat{\sigma} = percentile_{84^{th}} - percentile_{50^{th}}$$ 

```{r}
# calulate sigma
(sigma_hat <- 
   quantile(bursting_strengths_100_glass$bursting_strenths_psi, .84) -
   quantile(bursting_strengths_100_glass$bursting_strenths_psi, .50)
   )

sd(bursting_strengths_100_glass$bursting_strenths_psi)
```

Estimate the percentage of the containers would burst below LSL = 200 psi

```{r}
mean <- mean(bursting_strengths_100_glass$bursting_strenths_psi)
sd <- sd(bursting_strengths_100_glass$bursting_strenths_psi)

pnorm(q = 200, mean = mean, sd = sd, lower.tail = TRUE) * 100

```

skewness and kurtosis calculation: 

```{r}
data <- rnorm(n = 100)

m_j <- function(j) {
  (data - mean(data))^j %>%
  sum()/length(data)
} 

M <- map_dbl(1:4, ~m_j(.x)) 

(skewness <- (M[3]/(M[2])^1.5)^2 ) 

(kurtosis <- (M[4]/M[2])^2 ) 
```

## 8.3 Process Capability Ratios

### 8.3.1 Use and Interpretation of Cp

Process capability ration (PCR) $C_p$: 

$$C_p = \frac{(USL - LSL)}{6\sigma}$$

Where USL and LSL are the upper and lower specification limits, respectively. 

$$P = (\frac{1}{C_p}) * 100 = (\frac{1}{1.192})*100 = 83.89$$ 

It means a process uses 83.89% of the specification limits. 


### 8.3.2 Process Capability Ratio for an Off-Center Process

The process capability ratio $C_p$ does not take into account where the process mean is located relative to the specifications. $C_p$ simply measures the spread of the specifications relative to the six-sigma spread in the process. 

A new process capability ratio $C_{pk}$: 

$$C_{pk} = min(C_{pu}, C_{pl})$$

$$C_{pk} = min(C_{pu}, C_{pl})
         = min(C_{pu} = \frac{USL-\mu}{3\sigma}), C_{pl} = \frac{\mu - LSL}{3\sigma})
         = min(C_{pu} = \frac{62-53}{3*2}=1.5, C_{pl} = \frac{53-38}{3*2} = 2.5)
         = 1.5 $$

Cp measures **potential capability** in the process, wheres Cpk measumes **actual capability**. 




## 8.5 Process Capability Analysis Using Designed Experiments 

One of the major uses of designed experiments is to isolate and estimate the **source of variability** in a process. 

For example, consider a machine that fills bottles with a soft-drink beverage. Each machine has a large number of filling heads that must be independently adjusted. The quality characterisitc measured is the syrup content (in degrees brix) of the finished product. There can be variation in the observed brix ($\sigma_{B}^{2}$) because of machine variation ($\sigma_{M}^{2}$), head variability ($\sigma_{H}^{2}$), and alaytical test variability ($\sigma_{A}^{2}$). The variability in the obseved brix value is: 

$$\sigma_{B}^2 = \sigma_M^2 + \sigma_H^2 + \sigma_A^2$$




## 8.7 Gauge and Measurement System Capability Studies

### 8.7.1 Basic Concepts of Gauge Capability 

Determining the capability of the measurement system is an important aspect of many quality and process improvement activities. Generally, in any activity involving measurments, some of the observed variability will be inherent in the units or items that are being measured, and some of teh variability will result from the measurment system (method/analysis process) that is used. The purpose of most measurement systesm capability studies is to: 

* Determine how much of the total observed variability is due to the gauge or instrument or analysis process 

* Isolate the componenets of variability in the measurment system

* Assess whether the instrument or gauge or analysis process is capable (this is, is it suitable for the intended application).


An ineffective measurement system can dramatically impact business performance because it leads to uninformed (and usually bad) decision making. 


**Repeatability**: can we get the same observed value if we measure the same unit several times under identical conditions?

**Reproducibility**: how much difference in observed values do we experience when units are measured under different conditions, such as different operators, time periods, and so forth. 


These quantities answer only indirectly the fundamental questions: Is the system able to distinguish between good and bad units? 
It is very difficult to monitor, control, improve, or effectively manage a process with an inadequate measurement system. 


To introduce some of the basic ideas of measurement systems analysis (MSA) consider a simple model: 

$$y = x + \epsilon$$

where y is the total observed measurement, x is the true value of the measurement on a unit of product, and $\epsilon$ is the measurement error. We assume the x and $\epsilon$ are normally and indenpendently distributed random variables with means $\mu$ and 0 and variances ($\sigma_p^2$) and ($\sigma_{Gauge}^2$), respectively. The variance of the total observed measurement, y, is then: 

$$\sigma_{total}^2 = \sigma_P^2 + \sigma_{Gauge}^2$$. 

Control charts and other statistical methods can be used to seperate these components of variance, as well as to give an assessment of gauge capability. 


**EXample 8.7 Measuring Gauge Capability**

An instrument is to be used as part of a proposed SPC implementation. The quality-improvement team would like to get an assessment of gauge capability. Twenty (20) units of the product are obtained, and the process operator uses the instrument to measure each unit of product twice (2). 



```{r}
# read parts measurment data 
meas_data <- data.frame(part = rep(1:20, times = 1, each = 2), 
                        rep = rep(c("meas1", "meas2"), times = 20, each = 1), 
                        value = c(21, 20, 24, 23, 20, 21, 27, 27, 19, 18, 
                                  23, 21, 22, 21, 19, 17, 24, 23, 25, 23, 
                                  21, 20, 18, 19, 23, 25, 24, 24, 29, 30, 
                                  26, 26, 20, 20, 19, 21, 25, 26, 19, 19)
                        )

# Plot 
meas_data %>%
  ggplot(aes(x = part, y = value, col = rep)) + 
  geom_jitter(alpha = 0.5, height = 0) 

# calculate range and sd 
p_to_t <- meas_data %>%
  spread(key = rep, value = value ) %>%
  mutate(range = abs(meas1 - meas2)) %>%
  summarise(mean_r = mean(range)) %>%
  mutate(sigma_gauge = mean_r/1.128, 
         P_to_T = 6 * sigma_gauge/55) 

p_to_t

```

Values of the estimated ratio P/T of 0.1 of less often are taken to imply adequate gauge capability. This is based on the generally used rule that requires a measurment device to be calibrated in units one-tenth as large as teh accuracy required in the final measurment. 

Calculate total variance
```{r}
(var_total <- var(meas_data$value))

(var_gauge <- p_to_t$sigma_gauge^2)

(var_part <- var_total - var_gauge)

(sigma_part <- var_part^0.5)

```


It is also possible to design measurement systems capability studies to investigate two components or measurement error, commonly called the **repeatabiliyt** and the **reproducibility**. 

$$\sigma_{measurementError}^2 = \sigma_{Gauge}^2 = \sigma_{repeatability}^2 + \sigma_{reproducibility}^2$$

The experiment used to measure the components of $\sigma_{Gauge}^2$ is usually called a gauge R & R study, for the two components of $\sigma_{Gauge}^2$. 

### 8.7.2 The Analysis of Variance Method

```{r}
# (a) read the data
thermal_impedance_raw <- readxl::read_excel("data/ch08.xlsx",
                                            sheet = "table8_7") 

# (b) clean and reformat data
thermal_impedance <- str_split(thermal_impedance_raw$values, pattern = " " ) %>%
  map(as.numeric) %>%
  unlist() %>%
  as.data.frame() %>%
  select(thermal_impedance = '.')
 
thermal_impedance_df <-  
  data.frame(part = as.factor(rep(c(1:10), times = 1, each = 9)),
             operator = as.factor(rep(c(1:3), times = 10, each = 3)), 
             rep = as.factor(rep(c(1:3), times = 30, each = 1)), 
             thermal_impedance = thermal_impedance 
             )

thermal_impedance_df %>%
  ggplot(aes(x = part, y = thermal_impedance, col = operator)) +
  geom_jitter(alpha = 0.5, height = 0) 
```


* Randomly selected parts = p

* Randomly selected operators = o

* Each part measured times = n 

The measurement (i = part, j = operator, k = measurement) could be represented by the model: 

$$y_{ijk} = \mu + P_i + O_j + (PO)_{ij} + \epsilon_{ijk}$$ 

i = 1, 2, ..., p; j = 1, 2, .., 0; k = 1, 2, ..., n

Where the model paramters $P_i$, $O_j$, $PO_{ij}$, and $\epsilon$ are all indenpendent random variables that represent the effects of parts, operators, the interaction or joint effects of parts and operators, and random error. The is a **random effects model analysis of variance (ANOVA)**. 

```{r}
# build model 
model_thermal_impedance <- lm(thermal_impedance ~ part*operator, 
                              data = thermal_impedance_df)

# summary
summary(model_thermal_impedance)

# Note some error here to use "anova" by the normal way, because of repeated measurements. 
anova(model_thermal_impedance)

# Use the package, it is the best way if we don't want to control the calculation. 
SixSigma::ss.rr(var = thermal_impedance, 
                part = part, 
                appr = operator,
                lsl = 18, # lower specified limit
                usl = 58, # upper specified limit
                data = thermal_impedance_df)

(total_SS <- var(thermal_impedance_df$thermal_impedance)*89 )
```

$$\frac{P}{T} = \frac{6\hat\sigma}{USL-LSL} = \frac{6*1.34}{58-18}=0.27$$ 

By the standard measurems of gauge capability, this gauge would not be considered capable because the estimate of the P/T ratio exceeds 0.10. 



