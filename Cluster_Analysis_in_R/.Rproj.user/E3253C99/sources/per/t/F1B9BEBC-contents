---
title: "Cluster Analysis in R"
author: "Jeff Li"
date: "`r Sys.Date()`"
output: 
  html_document: 
    toc: true
    toc_depth: 3
    toc_float: true
---

"I maintained my edge by always being a student; you will always have something new to learn". - Jackie Joyner Kersee

Course Description: 

* Find groups of observations (clusters) that share similar characteristics

* learn hierarchical clustering 

* learn k-means clustering


Ref: Gorenshteyn, Dmitry. *https://www.datacamp.com/courses/cluster-analysis-in-r*.  2018.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## (I) Load Required Libraries
```{r, message = FALSE}
library(tidyverse)
library(dummies)
library(dendextend)
```


# 1. Calculating distance between observations

Objectives: 

* Learn how to calculate the distance between observations fro both continuous and categorical features

* Develop an intuition for how the scales of features can affect distance.


What is clustering? 

A form of exploratory data analysis (EDA) where **observations** are divided into meaningful groups that share common characteristics (features). 

Market segmentation and pattern grouping are both good examples where clustering is appropriate. 


## 1.1 Distance Between Observations and the scales of features 

```{r}
# (a) create a sample dataset
three_players <- tibble(x = c(5, 15, 0), y = c(4, 10, 20))

# (b) calculate distance 
dist(three_players)

# (c) create a sample dataset with different scale of features
three <- tibble(hight = c(5, 1, 2), weight = c(90, 92, 79))

dist(three)

dist(scale(three))

```


## 1.2 Measuring distance for categorical data

Calculating Jaccard Distance:  Intersection over Union. 


```{r}
# (a) Create a data frame

job_survey <- data.frame(job_satisfaction = c("Low", "Low", "Hi", "Low", "Mid"), 
                         is_happy         = c("No", "No", "Yes", "No", "No"))

job_survey


# Dummify the Survey Data
dummy_survey <- dummy.data.frame(job_survey)

# Calculate the Distance
dist_survey <- dist(dummy_survey, method = "binary")

# Print the Distance Matrix
dist_survey
```

No 1 and 2 are identical, so the distance is zero.


How to compare one observation to a pair of observations? The decision depends on the linkage method which we will show in the follow section. 



# 2. Hierarchical Clustering 

**Objectives:** 

* How to group similar observations (clusters)

* How to use linkage criterial and dendrogram plot 

# Lean to perform market segmentation of clients using their speding habits


## 2.1 Comparing more than two observations

**Likage Criteria**

* Complete linkage: maximum distance between two sets

* Single linkage: minimum distance between two sets

* Average linkage: average distance between two sets

The choice of the linkage method can change the clustering results. 


```{r}
# (a) read rds data file: the positions of 12 players

lineup <- read_rds("data/lineup.rds")

# Calculate the Distance
dist_players <- dist(lineup)

# Perform the hierarchical clustering using the complete linkage
hc_players_complete <- hclust(dist_players, method = "complete")

# Calculate the assignment vector with a k of 2
clusters_k2_complete <- cutree(hc_players, k = 2)

# Create a new dataframe storing these results
lineup_k2_complete <- mutate(lineup, cluster = clusters_k2_complete)

# Count the cluster assignments
count(lineup_k2_complete, cluster)

# Plot the positions of the players and color them using their cluster
ggplot(lineup_k2_complete, aes(x = x, y = y, color = factor(cluster))) +
  geom_point(size = 4, alpha = 0.7) +
  labs(title = "Complete linkage")
```

```{r}
# Perform the hierarchical clustering using the complete linkage
hc_players_average <- hclust(dist_players, method = "average")

# Calculate the assignment vector with a k of 2
clusters_k2_average <- cutree(hc_players_average, k = 2)

# Create a new dataframe storing these results
lineup_k2_average <- mutate(lineup, cluster = clusters_k2_average)

# Plot the positions of the players and color them using their cluster
ggplot(lineup_k2_average, aes(x = x, y = y, color = factor(cluster))) +
  geom_point(size = 4, alpha = 0.7) +
  labs(title = "Average Linkage")
```

```{r}
# Perform the hierarchical clustering using the complete linkage
hc_players_single <- hclust(dist_players, method = "single")

# Calculate the assignment vector with a k of 2
clusters_k2_single <- cutree(hc_players_single, k = 2)

# Create a new dataframe storing these results
lineup_k2_single <- mutate(lineup, cluster = clusters_k2_single)

# Plot the positions of the players and color them using their cluster
ggplot(lineup_k2_single, aes(x = x, y = y, color = factor(cluster))) +
  geom_point(size = 4, alpha = 0.7) +
  labs(title = "single Linkage")
```


**"complete** looks better than **"average"** or **"single"** based on what we expect from our data (6 vs 6 games). 


## 2.2 Dendrogram 

```{r}
par(mfrow = c(1, 3))
plot(hc_players_complete)
plot(hc_players_single)
plot(hc_players_average)
```


```{r}

dist_players <- dist(lineup, method = 'euclidean')
hc_players <- hclust(dist_players, method = "complete")

# Create a dendrogram object from the hclust variable
dend_players <- as.dendrogram(hc_players)

# Plot the dendrogram
plot(dend_players)

# Color branches by cluster formed from the cut at a height of 20 & plot
dend_20 <- color_branches(dend_players, h = 20)

# Plot the dendrogram with clusters colored below height 20
plot(dend_20)

# Color branches by cluster formed from the cut at a height of 40 & plot
dend_40 <- color_branches(dend_players, h = 40)

# Plot the dendrogram with clusters colored below height 40
plot(dend_40)

```

The height that we use to cut the tree greatly influences the number of clusters and their size. 

```{r}
dist_players <- dist(lineup, method = 'euclidean')
hc_players <- hclust(dist_players, method = "complete")

# Calculate the assignment vector with a h of 20
clusters_h20 <- cutree(hc_players, h = 20)

# Create a new dataframe storing these results
lineup_h20_complete <- mutate(lineup, cluster = clusters_h20)

# Calculate the assignment vector with a h of 40
clusters_h40 <- cutree(hc_players, h = 40)

# Create a new dataframe storing these results
lineup_h40_complete <- mutate(lineup, cluster = clusters_h40)


# Plot the positions of the players and color them using their cluster for height = 20
ggplot(lineup_h20_complete, aes(x = x, y = y, color = factor(cluster))) +
  geom_point()

# Plot the positions of the players and color them using their cluster for height = 40
ggplot(lineup_h40_complete, aes(x = x, y = y, color = factor(cluster))) + 
geom_point()

```


The height of any branch is determined by the linkage and distance decisions (in this case complete linkage and Euclidean distance). While the members of the clusters that form below a desired height have a maximum linkage distance amongst themselves.


## 2.3 Segment wholesale customers

We are going to hierarchical clustering to perform market segmentation (i.e. use consumer characteristics to group them into subgroups). --- a much simplifier case study. 

We have 45 different clients of a wholesale distributor for the food categories of *Milk*, *Grocery*, and *Frozen*.  All features are the same type (amount spent), so we don't need to scale it. 

```{r}
# (a) read data 
dir("data/")
customers_spend <- read_rds("data/ws_customers.rds")

# summary of data
summary(customers_spend)

# Distribution of data 
customers_spend %>%
  gather(key = "Items", value = "spent", Milk:Frozen) %>%
  ggplot(aes(x = spent, color = Items)) +
  geom_density()



```

```{r}
# Calculate Euclidean distance between customers
dist_customers <- dist(customers_spend)

# Generate a complete linkage analysis 
hc_customers <- hclust(dist_customers, method = "complete")

# Plot the dendrogram
plot(hc_customers)

# Create a cluster assignment vector at h = 15000
clust_customers <- cutree(hc_customers, h = 15000)

# Generate the segmented customers dataframe
segment_customers <- mutate(customers_spend, cluster = clust_customers)
```


```{r}

# Count the number of customers that fall into each cluster
count(segment_customers, cluster)

# Color the dendrogram based on the height cutoff
dend_customers <- as.dendrogram(hc_customers)
dend_colored <- color_branches(dend_customers, h = 15000)

# Plot the colored dendrogram
plot(dend_colored)

# Summary for each category
segment_customers %>% 
  gather(key = "items", value = "spent", Milk:Frozen) %>%
  group_by(cluster, items) %>% 
  summarise(n = n(), 
            mean = mean(spent)) %>%
  gather(key = "key", value = "value", n:mean) %>%
  unite(items_stat, items:key) %>%
  spread(key = items_stat, value = value) %>%
  select(cluster, 
         n = Frozen_n, 
         ends_with("mean"))
```

* Customers in cluster 1 spent more money on Milk than any other cluster.

* Customers in cluster 3 spent more money on Grocery than any other cluster.

* Customers in cluster 4 spent more money on Frozen goods than any other cluster.

* The majority of customers fell into cluster 2 and did not show any excessive spending in any category.

