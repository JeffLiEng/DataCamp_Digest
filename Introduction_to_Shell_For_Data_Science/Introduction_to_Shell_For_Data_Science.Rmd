---
title: "Introduction to Shell for Data Science"
author: "Jeff Li"
date: "`r Sys.Date()`"
output: 
  html_document: 
    toc: true
    toc_depth: 3
    toc_float: true
---

"I maintained my edge by always being a student; you will always have something new to learn". - Jackie Joyner Kersee


**Course Description**

""

Note: Some course materials and data have been revised for training by Jeff Li. 


# 1. Manipulating files and directories

The most common interface is a graphical file explorer, which translates clicks and double-clicks into commands to open files and run programs. 

**command-line shell**: Spell out what you want to the computer to do. 

## 1.1 pwd and ls

* *pwd* - short for "print working directory"

* *ls* - short for "listing". Lists the contents of the current directory.  *ls* with an appropriate argument to list the files in the directory. 


## 1.2 relative path and absolute path

An absolute path is like a latitude and longitude: it has the same value no matter where you are.  It always begins with */*. 

A relative path: specifies a location starting from where you are: it's like saying "20 kilometers north". 


## 1.3 Move to another directory 

* **cd** - change directory 

* a special path .. (two dots with no spaces) --means "the directory above the one I'm currently in". 

* another special path: ~ (the tilde character), which means "my home directory". No matter where you are ls ~ will always list the contents of your home directory, and "cd ~" will always take you home. 

## 1.4 Copy files and move files

* **cp**: short for "copy". 

* **mv**: moves files from one directory to another.  For example: "mv test1.txt duplicate.txt ..", which moves the files from current working directory up one level

## 1.5 Renames files, delete files

* **mv** can also be used to rename files. 
for example: mv course.text old-course.txt

* **rm**: which stands for "remove". 

*mv* treats directories the same way it treats files: if you are in your home directory and run *mv seasonal by_season*, *mv* changes the name of the *seasonal* directory to *by_season*. 

If you try to *rm* a directory, the shell prints an error message telling you it can't do that, primarily to stop you from accidentally deleting an entire directory full of work. Instead, you can use a separate command called *rmdir*. For added safety, it only works when the directory is empty. 



# 2. Manipulating data

## 2.1 View a file's contents

* *cat*: prints the contents of files onto the screen. (its name is short for "concatenate", meaning "to link things together"). 

## 2.2 View a file's contents piece by piece

You can use "cat" to print large files and then scroll through the output, but it is usually more convenient to *page* the output. 

* *less* a file, one page is displayed at a time; you can press space-bar to page down or type *q* to quit


If you give *less* the names of several files, you can type *:n* (colon and a lower-case 'n') to move to then next file, *:p* to go back to the previous one, or *:q* to quit. 


## 2.3 Look at the start of a file

* **head**: prints the first few lines of a file(where "a few" means 10)


## 2.4 How can I type less? 

One of the shell's power tools is *tab completion*.


## 2.5 Control what commands do - command line flag

*command-line flag*: A flag's name usually indicates its purpose (for example, -n is meant to signal "number of lines"). 

Note: it's considered good style to put all flags before any filenames. 

## 2.6  List everything below a directory? 

In order to see everything underneath a directory, no matter how deeply nested it is, you can give *ls* the flag *-R* (which means "recursive"). 

*ls* has another flag *-F* that prints a */* after the name of every directory and a \* after the name of every runnable program. 

*man* : short for "manual". 


## 2.6 Select columns from a file 

* **cut**: cut -f 2-5, 8 -d , values.csv, which means "select columns 2 through 5 and columns 8, using comma as the separator".  *cut* uses *-f* (meaning "fields") to specify columns and *-d* (meaning "delimiter") to specify the separator. We need to specify the latter because some files may use spaces, tabs, or colons to separate columns. 


## 2.7 Repeat commands

*history* will print a list of commands we have run recently. Each one is preceded by a serial number to make it easy to re-run particular commands: for example *!55*. 


## 2.8 Select lines containing specific values

*grep* selects lines according to what they contain. For example, *grep bicuspid seasonal/winter.csv*

grep's common flags:

* -c : print a count of matching lines rather than the lines themselves

* -h: do not print the names of files when searching multiple files

* -i: ignore case

* -l: print the names of files that contain matches, not the matches

*-n: print line numbers for matching lines

*-v: invert the match, i.e., only show lines that don't match. 


# 3. Combining tools 

## 3.1 Store a command's output in a file


* head -n 5 seasonal/summer.csv > top.csv

* tail -n 5 seasonal/summer.csv > last.csv


## 3.2 Use a command's output as an input

How to get lines from the middle of a file. 

* head -n 5 seasonal/winter.csv > top.csv

* tail -n 3 top.csv

## 3.3 Combine commands

Using redirection to combine commands has two drawbacks:

* It leaves a lot of intermediate files lying around

* the commands to produce the final result are scattered across several lines of history

The shell provides another tool that solves both of these problems at once called a *pipe*. 

*head -n seasonal/summer.csv | tail -n 3* 

The *pipe* symbol tells the shell to use the output of the command on the left as the input to the command on the right. 


Use cut to select all of the tool names from column 2 of the comma delimited file. 

*cut -d , -f 2 seasonal/summer.csv | gre -v Tooth*

We can chain any number of commands together. For example: 

*cut -d, -f 1 seasonal/spring.csv | grep -v Date | head -n 10*  will select the first column from the spring data; remove the header line containing the word "Date"; and select the first 10 lines of actual data. 

Exercise: *cut -d , -f 2 seasonal/summer.csv | grep -v Tooth | head -n 1*

By chaining several commands together, we can build powerful data manipulation pipelines. 


## 3.4 Count the records in a file

The command *wc* (short for "word count") prints the number of characters, words, and lines in a file. 

* *-c*, *-w*, and *-l*: characters, words, and lines, respectively. 


Exercise: 

*grep 2017-07 seasonal/spring.csv | wc -l*

*cut -d , -f 2 seasonal/winter.csv | grep -v Tooth | sort | uniq -c*




## 3.5 Specify many files at once

*cut -d, -f 1 seasonal/winter.csv seasonal/spring.csv*

But typing the names of many files over and over is a bad idea: it wastes time. Using *wildcards* to specify a list of files with a single expression. The most common wildcards is *, which means "match zero or more characters". 

*cut -d, -f 1 seasonal/** 

exercise: 
*head -n 3 seasonal/s*.csv*

## 3.6 Other wildcards 

* ? matches a single character

* [...] matches any one of the characters inside the square brackets, so 201[78].txt matches 2017.txt or 2018.txt. 

* {...} matches any the comma-separated patterns inside the curly brackets, so *{*.txt, *.csv}* matches any file whose names ends with .txt or .csv, but not files whose names end with .pdf. 


## 3.7 Sort lines of text

* *sort*. the flags *-n* and *-r* can be used to sort numerically and reverse the order of its output, while *-b* tells it to ignore leading blanks and *-f* tells it to fold case (i.e. be case-insensitive). 

Pipelines often use *grep* to get rid of unwanted records and then *sort* to put the remaining records in order. 

*cut -d , -f 2 seasonal/summer.csv | grep -v Tooth*

*cut -d , -f 2 seasonal/winter.csv | grep -v Tooth | sort -r* 


## 3.8 remove duplicate lines

* *uniq*: to remove duplicated lines. 


## 3.9 Stop a running program

* *Ctrl-C* to end 


## 3.10 Wrapping up

* use wc to list the number lines 
   *wc -l seasonal//**


# 4. Batch processing 

Most shell commands will process many files at once. This chapter is to show to make our own pipelines to do that. Along the way, we will see how the shell uses variables to store information

* *set | grep HISTFILESIZE*  :  show the old commands on this system. 

## 4.1 Print a variable's value

* use a command called *echo* to print its arguments

* echo $HOME

* *echo $USER*

* *echo $SHELL* 

* *echo $OSTYPE* : the name of the kind of operating system

## 4.2 How does the shell store information? 

*shell variable*: is like a local variable in a programming language. 

To create a shell variable, simply assign a value to a name: 
*training=seasonal/summer.csv* 
check the variable's value with: 
*echo $training* 

*head -n 1 $training* 


## 4.3 Repeat a command many times

Example: *for filetype in gif jpg png; do echo $filetype; done* 

* The structure is *for ...variable... in ...list...; do ...body...; done*

* The list of things the loop is to process

First-rate for looping! Loops are brilliant if you want to do the same thing hundreds or thousands of times. 


## 4.4 Record the names of a set of files

People often set a variable using a wildcard expression to record a list filenames. For example: 

*datasets=seasonal/*.csv* 

*for filename in $datasets; do echo $filenames; done*

## 4.5 Run many commands in a single loop

prints the second line of each data file: 
* for file in seasonal/*.csv; do head -n 2 $file | tail -n 1; done 


* for files in seasonal/*.csv; do grep -h 2017-07 $files


## 4.6 Don't use spaces in filenames

It is  easy and sensible to give files multi-word names like *July 2017.csv* in a graphic file explorer. 


## 4.7 Do many things in a single loop

* for f in seasonal/*.csv; do echo $f; head -n 2 $f | tail -n 1; done


# 5. Creating new tools 

## 5.1 Edit a file

Use a simple text editors *Nano* to edit.

*nano names.txt* 

* Ctrl-K: delete a line

* Ctrl-U: un-delete a line

* Ctrl-O: save the file ('O' stands for 'Output')

* Ctrl-X: exit the editor


*copy files to home directory*

cp seasonal/s* ~ 


## 5.2 Record the history

1. Run *history*
2. Pipe its output to *tail -n 10* (or however many recent steps you want to save)
3. Redirect that to a file called somthing like *figure-5.history*

This is better than writing things down in a lab notebook because it is guaranteed not to miss any steps. 

## 5.3 Save commands to re-run later

1. Use *nano dates.sh* to create a file called *dates.sh* that contain this command: *cut -d , -f seasonal/*.csv* 
2. then *bash dates.sh*


## 5.4 Re-use pipes 

scripts can also contain pipes. For example, if *all-dates.sh* contains this line: 
cut -d , -f 1 seasonal/*.csv | grep -v Date | sort | uniq

then: 

bash all-dates.sh > dates.out

will extract the unique dates from the seasonal data files and save them in *dates.out*

## 5.5 Pass filenames to scripts

special expression $@ (dollar sign immediately followed by at-sign) to mean "all of the command-line paramters given to the script". For example, if *unique-lines.sh* contains this: 

sort $@ | uniq

then when you run: 

bash unique-lines.sh seasonal/summer.csv 

the shell replances $@ with seasonal/summer.csv adn processes one file. 

## 5.6 How to process a single argument

As well as $@, the shell lets you use $1, $2, and so on to refer to specific command-line parameters. We can use this to write commands that feel simpler or more natural than the shell's. 

## 5.7 Use one shell script do many things

A script can contain many lines of commands. For example, you can create one that tells you how many records are in the shortest and longest of your data files, i.e., the range of your datasets' lengths.



