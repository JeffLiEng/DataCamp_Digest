---
title: "Working with Dates and Times in R "
author: "Jeff Li"
date: "`r Sys.Date()`"
output: 
  html_document: 
    toc: true
    toc_depth: 3
    toc_float: true
---

"I maintained my edge by always being a student; you will always have something new to learn". - Jackie Joyner Kersee


**Course Description**

"Dates and times are abundant in data and essential for answering questions that start with when, how long, or how often. However, they can be tricky, as they come in a variety of formats and can behave in unintuitive ways. This course teaches you the essentials of parsing, manipulating, and computing with dates and times in R. By the end, you'll have mastered the lubridate package, a member of the tidyverse, specifically designed to handle dates and times. You'll also have applied your new skills to explore how often R versions are released, when the weather is good in Auckland (the birthplace of R), and how long monarchs ruled in Britain. "

Ref: Wickham, Charlotte (2018) Working with Dates and Times in R, www.datacamp.com, 2018.

Charloote Wickham, an assistant Professor at Oregon State University, is passionate about teaching. I want to learn here teaching style. 


Note: Some course materials and data have beem digested for training. 

# (I) Load required libraries
```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(lubridate)
library(anytime)
library(tidyverse)
library(ggridges)
library(fasttime)
library(microbenchmark)

```


# 1. Dates and Times in R

Objective: 

* Learn the ways that R stores data and times

"R doesn't know something is a date or time unless you tell it. In this chapter you'll learn about some of the ways R stores dates and times by exploring how often R versions are released, and how quickly people download them. You'll also get a sneak peek at what you'll learn in the following chapters."


For **Dates**, different conventions in different places. Such as 27th Feb 2013, 27/2/2013, 2/27/2013, 2013-02-27. The global standard numeric date format: ISO 8601 YYYY-MM-DD (for example 1982-07-12, it is my friend's birthday!). 


* ordered from the largest to smallest unit of time

* has a fixed number of digits


## 1.1 Dates in R

```{r}
2003-02-27  # not correct input
"2003-02-27" # not correct input
str("2003-02-27")
as.Date("2003-02-27")
str(as.Date("2003-02-27"))
```
Packages that import dates: *readr*, *anytime*


Dates act like numbers.  Date objects are stored as days since 1970-01-01. 
```{r}
as.Date("2003-02-27") > as.Date("2002-02-27")
as.Date("2003-02-27") + 1
as.Date("2003-02-27") - as.Date("2002-02-27")
```

How to plot dates?
```{r}
x <- c(as.Date("2003-02-27"), 
       as.Date("2003-03-27"), 
       as.Date("2003-04-27"))

plot(x, 1:3)

ggplot() +
  geom_point(aes(x = x, y =1:3))
```



```{r}
#-------------------------------------- 
# The date R 3.0.0 was released
x <- "2013-04-03"

# Examine structure of x
str(x)
```

```{r}
# Use as.Date() to interpret x as a date
x_date <- as.Date(x)

# Examine structure of x_date
str(x_date)

# Store April 10 2014 as a Date
april_10_2014 <- as.Date("2014-04-10")

class(april_10_2014)
```

```{r}
#-------------import with readr and anytime packages---------------
# Use read_csv() to import rversions.csv
releases <- read_csv("data/rversions.csv", col_types = list(col_integer(), 
                                                        col_integer(), 
                                                        col_integer(),
                                                        col_date(format = ""),
                                                        col_datetime(format = ""), 
                                                        col_time(format = ""), 
                                                        col_character()))

head(releases)
# Examine the structure of the date column
str(releases$date)
```

```{r}
# Various ways of writing Sep 10 2009
sep_10_2009 <- c("September 10 2009", "2009-09-10", "10 Sep 2009", "09-10-2009")

# Use anytime() to parse sep_10_2009
anytime(sep_10_2009)
```

```{r}

#----plotting with dates------------------

# Set the x axis to the date column
releases %>%
  ggplot(aes(x = date, y = type)) +
  geom_line(aes(group = 1, color = factor(major)))

# Limit the axis to between 2010-01-01 and 2014-01-01
ggplot(releases, aes(x = date, y = type)) +
  geom_line(aes(group = 1, color = factor(major))) +
  xlim(as.Date("2010-01-01"), as.Date("2014-01-01"))

# Specify breaks every ten years and labels with "%Y"
ggplot(releases, aes(x = date, y = type)) +
  geom_line(aes(group = 1, color = factor(major))) +
  scale_x_date(date_breaks = "10 years", date_labels = "%Y")
```

```{r}
#---Arithmetic and logical operators -------------
# Find the largest date
last_release_date <- max(releases$date)

# Filter row for last release
last_release <- filter(releases, date == last_release_date)

# Print last_release
last_release

# How long since last release?
Sys.Date() - last_release_date

```

## 1.2 Times

ISO 8601: HH::MM:SS 

* HH: 00 - 24

* MM: 00 - 59

* SS: 00 -- 60


Timezones: 

* local time: "2013-02-27T18:00:00"  6 pm local time

* UTC: "2013-02-27T18:00:00Z" - 6 pm UTC

* "2013-02-27T18:00:00-08:00" - 6 pm in Oregon


```{r}
as.POSIXct("2013-02-27T18:00:00Z")
as.POSIXct("2013-02-27T18:00:00Z", tz = "UTC")
```

Datetimes behave nicely too: compared, subtracted, plotted. 



There are two objects types: 

* **POSIXlt** - list with named components   (*lt* = List Time or local time )

* **POSIXct** - seconds since 1970-01-01 00:00:00  (*ct* = Continuous Time or calendar time)

`as.POSIXct()` - Turns a string into a POSIXct object. 

Timezones: 

* as.POSIXct("2013-02-27T18:00:00Z", tz = "UTC")   # add tz argument to change timezones

Check your tiemzone with: `Sys.timezone()`

```{r}
# Use as.POSIXct to enter the datetime 
as.POSIXct("2010-10-01 12:12:00")

# Use as.POSIXct again but set the timezone to `"America/Los_Angeles"`
as.POSIXct("2010-10-01 12:12:00", tz = "America/Los_Angeles")
```

```{r}
# Use read_csv to import rversions.csv
releases <- read_csv("data/rversions.csv")

# Examine structure of datetime column
str(releases$datetime)
```

```{r}

# ---------------import and plot --------------
# Import "cran-logs_2015-04-17.csv" with read_csv()
logs <- read_csv("data/cran-logs_2015-04-17.csv")

# Print logs
logs

# Store the release time as a POSIXct object
release_time <- as.POSIXct("2015-04-16 07:13:33", tz = "UTC")

# When is the first download of 3.2.0?
logs %>% 
  filter(datetime > release_time,
    r_version == "3.2.0") %>%
  head(n = 3)

# Examine histograms of downloads by version
ggplot(logs, aes(x = datetime)) +
  geom_histogram() +
  geom_vline(aes(xintercept = as.numeric(release_time)))+
  facet_wrap(~ r_version, ncol = 1)
```

As shown in the figures, it only takes about two days for downloads of the new version(3.2.0) to overtake downloads of the old version (3.1.3). 



# 2. Parsing and Manipulating Dates and Times with lubridate

"Dates and times come in a huge assortment of formats, so your first hurdle is often to parse the format you have into an R datetime. This chapter teaches you to import dates and times with the lubridate package. You'll also learn how to extract parts of a datetime. You'll practice by exploring the weather in R's birthplace, Auckland NZ."

Objectives: 

* learn how to import dates and times

* learn how to extract parts of datetime 



## 2.1 Why lubridate? 

* Make working with dates and times in R easy

* Consistent behaviour regardless of underlying object
```{r}
ymd("2013-02-27")
dmy("27/2/2013")
parse_date_time(
  c("Feb 27th, 2017", "27th Feb 2017"), 
  order = c("mdy", "dmy"))
```

Manipulating datetimes
```{r}
# read csv
akl_daily <- read_csv("data/akl_weather_daily.csv")
head(akl_daily)

# manipulate datetimes
akl_daily <- akl_daily %>%
  mutate(
    year = year(date), 
    yday = yday(date), 
    month = month(date, label = TRUE)
  )

head(akl_daily)
```


## 2.2 ymd() and parse_date_time() functions 
```{r ymd}
# Parse x 
x <- "2010 September 20th" # 2010-09-20
ymd(x)

# Parse y 
y <- "02.01.2010"  # 2010-01-02
dmy(y)

# Parse z 
z <- "Sep, 12th 2010 14:00"  # 2010-09-12T14:00
mdy_hm(z)
```

```{r parse_date_time}
#---parse_date_time()-----------------------
# Specify an order string to parse x
x <- "Monday June 1st 2010 at 4pm"
parse_date_time(x, orders = "amdyIp")    # a - Abbrevated weekday, y - year with century, I - Hours (12 hour), p - AM/PM

# Specify order to include both "mdy" and "dmy"
two_orders <- c("October 7, 2001", 
                "October 13, 2002", 
                "April 13, 2003", 
                "17 April 2005", 
                "23 April 2017")

parse_date_time(two_orders, orders = c("mdy","dmy"))

# Specify order to include "dOmY", "OmY" and "Y"
short_dates <- c("11 December 1282", "May 1372", "1253")

parse_date_time(short_dates, orders = c("dOmY", "OmY","Y"))

```


## 2.3 Practice: Weather in Auckland 
### 2.3.1 Daily data 
```{r}

# make_date(year, month, day)  and make_datetime
make_date(2018, 11, 29)
make_datetime(2018, 11, 29, 21, 14, 0)

# Import CSV with read_csv()
akl_daily_raw <- read_csv("data/akl_weather_daily.csv")

# Print akl_daily_raw
head(akl_daily_raw)

# Parse date 
akl_daily <- akl_daily_raw %>%
  mutate(date = ymd(date))

# Print akl_daily
head(akl_daily)

# Plot to check work
ggplot(akl_daily, aes(x = date, y = max_temp)) +
  geom_line() 

```

It is not so hot in Auckland, and less than 80 F. Summer falls in Dec-Jan-Feb. 

### 2.3.2 Hourly data
```{r}
# import hourly data
akl_hourly_raw <- read_csv("data/akl_weather_hourly_2016.csv")

# Print the head of data
head(akl_hourly_raw)

# use make_date() to combine year, month and mday
akl_hourly <- akl_hourly_raw %>%
  mutate(date = make_date(year = year, month = month, day = mday))

# Parse datetime_string
akl_hourly <- akl_hourly %>%
  mutate(
    datetime_string = str_c(date, time, sep="T"), 
    datetime = ymd_hms(datetime_string)
  )

head(akl_hourly)


# Print date, time and datetime columns of akl_hourly
akl_hourly %>% select(date, time, datetime)

# Plot to check work
ggplot(akl_hourly, aes(x = datetime, y = temperature)) +
  geom_line()
```

It's interesting how the day to day variation is about half the size of the yearly variation. 


### 2.3.3 Extracting parts of a datetime

* basic functions: year(), month(), day(), hour(), min(), second(), wday(), yday(), and tz

* other might be useful functions: leap_year() - TRUE or FALSE, am(), pm(), dst(), quarter() - 1/2/3/4, semester() - 1/2. 

```{r}
# Examine the head() of release_time
release_time <- releases$datetime
head(release_time)

# Examine the head() of the months of release time
head(month(release_time))

# Extract the month of release
month(release_time) %>% table()

# Extract the year of release
year(release_time) %>% table()

# how ofter is the hour before 12 (noon)? 
mean(hour(release_time) < 12)

# How ofter is the release in am?
mean(am(release_time))
```

Adding useful labels
```{r add_labels}
# Use wday() to tabulate release by day of the week
wday(releases$datetime) %>% table()

# Add label = TRUE to make table more readable
wday(releases$datetime, label = TRUE) %>% table()

# create column wday to hold labelled week days
releases$wday <- wday(releases$datetime, label = TRUE)

# plot barchart of weekday by types of release

ggplot(releases, aes(x = wday)) +
  geom_bar() +
  facet_wrap( ~ type, ncol = 1, scale = "free_y")


```

Looks like not too many releases occur on the weekends, and there is quite a different weekday pattern between minor and patch releases. 


### 2.3.4 Extracting and explore weather in Auckland
```{r}
# Add columns of year, yday and month
akl_daily <- akl_daily %>%
  mutate(
    year = year(date), 
    yday = yday(date), 
    month = month(date, label = TRUE))

# Plot max-temp by yday for all years
ggplot(akl_daily, aes(x = yday, y = max_temp)) + 
  geom_line(aes(group = year), alpha = 0.5)

# Examine distribution of max_temp by month
ggplot(akl_daily, aes(x = max_temp, y = month, height = ..density..)) +
  geom_density_ridges(stat = "density")

```

Looks like Jan, Feb and Mar are great months to visit Aukland because it has warm temperatures. 


### 2.3.5 Extracting and summarize

How many days in each month there was any rain during the day? 

```{r}
akl_daily %>% 
  group_by(month) %>%
  summarise(sum(events == "Rain", na.rm = TRUE)/n())

# Create new columns hour, month and rainy
akl_hourly <- akl_hourly %>%
  mutate(
    hour = hour(datetime),
    month = month(datetime, label = TRUE),
    rainy = weather == "Precipitation")

# Filter for hours between 8am and 10pm (inclusive)
akl_day <- akl_hourly %>% 
  filter(hour>= 8, hour <= 22)

# Summarise for each date if there is any rain
rainy_days <- akl_day %>% 
  group_by(month, date) %>%
  summarise(
    any_rain = any(rainy)
  )

# Summarise for each month, the number of days with rain
rainy_days %>% 
  summarise(
    days_rainy = sum(any_rain)
  )

```


### 2.3.6 Rounding versum extracting 
```{r}
head(release_time) %>% hour()

head(release_time) %>% floor_date(unit = "hour")
```

Rounding in lubridate:  round_date() - round to nearest; ceiling_date() - round up; floor_date() - round to down. 

Possible values of unit: second, minute, hour, day, week, month, bimonth, quartr, halfyear, year, 2 years, 5 minutes. 

```{r}
r_3_4_1 <- ymd_hms("2016-05-03 07:13:28 UTC")

# Round down to day
floor_date(r_3_4_1, unit = "day")

# Round to nearest 5 minutes
round_date(r_3_4_1, unit = "5 minutes")

# Round up to week 
ceiling_date(r_3_4_1, unit = "week")

# Subtract r_3_4_1 rounded down to day
r_3_4_1 - floor_date(r_3_4_1, unit = "day")
```

Rounding with the weather data

```{r}
# Create day_hour, datetime rounded down to hour
akl_hourly <- akl_hourly %>%
  mutate(
    day_hour = floor_date(datetime, unit = "hour")
  )

# Count observations per hour  
akl_hourly %>% 
  count(day_hour) 

# Find day_hours with n != 2  
akl_hourly %>% 
  count(day_hour) %>%
  filter(n != 2) %>% 
  arrange(desc(n))
```

Yay! 92 hours that don't have two measurements. Interestingly there are four measurements on 2016-04-03 and 2016-09-25, they happen to be the days Daylight Saving starts and ends.


# 3. Arithmetic with Dates and Times

## 3.1 Taking differences of datatimes 
### 3.1.1 lecture
```{r}
# (a) read data
releases <- read_csv("data/rversions.csv")
last_release <- releases %>% filter(date == max(date))

# (b) easy way but not smart way
Sys.Date() - last_release$date

# (c) better way
difftime(Sys.Date(), last_release$date)

# (d) with different units = "secs", "hours", "days", or "weeks"
difftime(Sys.Date(), last_release$date, units = "secs")
difftime(Sys.Date(), last_release$date, units = "weeks")

# (e) function of now() and today()
today()
str(today())

now()
str(now())
```

### 3.1.2 practice - How long has it been? 

```{r}
# the date of Apollo 11 landed and moment of setp 
data_landing <- mdy("July 20, 1969")
# Neil Armstrong stepped onto the surface
moment_step <- mdy_hms("July 20, 1969, 02:56:15", tz = "UTC")  

# How many days since the first man on the moom?
difftime(today(), data_landing, units = "days") 

# How many seconds since the first man on the moom? 
difftime(now(), moment_step, units = "secs")

```

How many seconds in a day? 
```{r}
# Three dates
mar_11 <- ymd_hms("2017-03-11 12:00:00", tz = "America/Los_Angeles")
mar_12 <- ymd_hms("2017-03-12 12:00:00", tz = "America/Los_Angeles")
mar_13 <- ymd_hms("2017-03-13 12:00:00", tz = "America/Los_Angeles")

# Difference between may_13 and mar_12 in seconds
difftime(mar_13, mar_12, units = "secs")

# Difference between may_12 and mar_11 in seconds
difftime(mar_12, mar_11, units = "secs")
```


## 3.2 Time spans
### 3.2.1 Time Spans - lecture

* period - human concept of a time span

* duration - stopwatch concept of a time span

```{r}
# Creating a time  span
days()
days(x = 2)
ddays(2)

# Arithmetic with time spans
2 *days()
days() + days()
ymd("2011-01-01") + days()

# function to create time spans - duration
dseconds()
dminutes()
dhours()
ddays()
dweeks()
dyears()

# function to create time spans - Period
seconds()
minutes()
hours()
days()
weeks()
months(x = 1, abbreviate = TRUE)
years()

```

### 3.2.2 Time spans - practice
```{r}
# Add a period of one week to mon_2pm
mon_2pm <- dmy_hm("27 Aug 2018 14:00")
mon_2pm + weeks(x = 1)

# Add a duration of 81 hours to tue_9am
tue_9am <- dmy_hm("28 Aug 2018 9:00")
tue_9am + dhours(x = 81)

# Subtract a period of five years from today()
today() - years(x = 5)

# Subtract a duration of five years from today()
today() - dyears( x = 5)

```

When dealing with human interpretations of dates and time you want to use periods. 


```{r}
# Time of North American Eclipse 2017
eclipse_2017 <- ymd_hms("2017-08-21 18:26:40")

# Duration of 29 days, 12 hours, 44 mins and 3 secs (A Synodic month being the period of the Moon's phases)
synodic <- ddays(x = 29) + dhours(x = 12) + dminutes(x = 44) + dseconds(x = 3)
synodic

# 223 synodic months (A Saros is a length of time that corresponds to 223 Synodic months)
saros <- 223 * synodic

# Add saros to eclipse_2017
eclipse_2017 + saros
```

### 3.2.3 Generating sequences of datetimes
```{r}
# generate a sequence of periods from 1 day up to 10 days
1:10 * days(x = 1)
today() + 1:10 * days(x = 1)

# Add a period of 8 hours to today
today_8am <- today() + hours(x = 8)

# sequence of two weeks from 1 to 26
1:26 * weeks(x = 2)

# Create datatime for every two weeks for a year
today_8am + 1:26 * weeks(x = 2)

```

### 3.2.4 The tricky thing about months

```{r}
# lubridate returns the same day of the month in the next month, but since the 31st of February doesn't exist, it returns NA
ymd("2018-01-31") + months(1)

# %m+% and %m-%: roll back to the last existing date

# A sequence of 1 to 12 periods of 1 month
month_seq <- 1:12 * months(x = 1)

# Add 1 to 12 months to jan_31
jan_31 <- ymd("2018-01-31")

jan_31 + month_seq

# Replace + with %m+%
jan_31 %m+% month_seq

# Replace + with %m-%
jan_31 %m-% month_seq


# Be caution with %m-% and %m+%
jan_31 %m+% months(1) %m-% months(1)  # I didnot get jan_31 back

add_with_rollback(e1 = jan_31, e2 = months(1), roll_to_first = FALSE)

```


## 3.3 Intervals
### 3.3.1 Lecture: Creating intervals, Operating on an interval, comparing intervals

Which kid of time span to use? 

* **Intervals** when you have a start and end

* **Periods** when you are interested in human units

* **Durations** if you are interested in seconds elapsed


```{r}
# two ways to create intervals
dmy("5 January 1961") %--% dmy("30 January 1969")
interval(dmy("5 January 1961"), dmy("30 January 1969"))

# operating on an interval 
beatles <- dmy("5 January 1961") %--% dmy("30 January 1969")

int_start(beatles)
int_end(beatles)
int_length(beatles)
as.period(beatles)
as.duration(beatles)

# comparing intervals
hendrix_at_woodstock <- mdy("August 17 1969")
hendrix_at_woodstock %within% beatles

hendrix <- dmy("01 October 1966") %--% dmy("16 September 1970")
int_overlaps(beatles, hendrix)

```

### 3.3.2 Examining intervals. Reigns of kings and queens

```{r}
dir("data/")
```


# 4. Problems in practice

## 4.1 Time zones - Lecture
```{r}
# time zones 
Sys.timezone()

# IANA Timezones
length(OlsonNames())
head(OlsonNames())
tail(OlsonNames())

# Setting and extracting 
mar_11 <- ymd_hms("2017-03-11 12:00:00", tz = "America/Los_Angeles")
mar_11
tz(mar_11)

# Manipulateing timezones
force_tz(mar_11, tzone = "America/New_York")

# View the same instant in a different timezone
with_tz(mar_11, tzone = "America/New_York")
```

## 4.2 setting the timezone, Viewing in a timezone

### 4.2.1 Setting the timezone

* to correct wrong timezone, set it with force_tz(). Timezone needs to be one from OlsonNames()

```{r}
# Game2: CAN vs NZL in Edmonton
game2 <- mdy_hm("June 11 2015 19:00")

# Games3: CHN vs NZL in Winnipeg
game3 <- mdy_hm("June 15 2015 18:30")

# Set the timezone to "America/Edmonton"
game2_local <- force_tz(game2, tzone = "America/Edmonton")
game2_local

# Set the timezone to "America/Winnipeg"
game3_local <- force_tz(game3, tzone = "America/Winnipeg")
game3_local

# Hong long does the team have to rest? 
as.period(interval(game2_local, game3_local))
```

### 4.2.2 Viewing in a timezone
```{r}
# the difference between now() displayed in the "America/Los_Angeles" timezone and "Pacific/Auckland" timezone:
now <- now()
with_tz(now, "America/Los_Angeles") - with_tz(now, "Pacific/Auckland")

# What time is game2_local in NZ?
with_tz(game2_local, tzone = "Pacific/Auckland")

# what time is game2_local in Corvallis, Oregan
with_tz(game2_local, tzone = "America/Los_Angeles")

# waht time is game3_local in NZ?
with_tz(game3_local, tzone = "Pacific/Auckland")
```

### 4.2.3 Timezones in the weather data
```{r}
# Hourly Auckland weather data 
akl_hourly <- read_csv("data/akl_weather_hourly_2016.csv") %>%
  mutate(date = make_date(year = year, month = month, day = mday), 
        datetime_string = str_c(date, time, sep = "T"), 
        datetime = ymd_hms(datetime_string))

glimpse(akl_hourly)

# Examine datetime and date_utc columns
head(akl_hourly$datetime)
head(akl_hourly$date_utc)

# Force datetime to Pacific/Auckland
akl_hourly <- akl_hourly %>%
  mutate(datetime = force_tz(datetime, tzone = "Pacific/Auckland"))

# Reexame datetime
head(akl_hourly$datetime)

# Are datetime and date_utc the same moments
table(akl_hourly$datetime-akl_hourly$date_utc)
```

There are 17,450 rows *datetime* and *date_utc* describe the same moment, but for 4 rows they are different because of DST. 

### 4.2.4 Times without dates
```{r}
# Examine structure of time column 
str(akl_hourly$time)

# Examine head of time column
head(akl_hourly$time)

# A plot using just time
ggplot(akl_hourly, aes(x = time, y = temperature)) + 
  geom_line(aes(group = date), alpha = 0.2)
```

Using time without date is a great way to examine daily patterns. 

## 4.3 More on importing and exporting datetimes
### 4.3.1 Lectures
```{r}
# Fast parsing is better option, becuase parse_date_time() can be slow because it's designed to be forgiving and flexible. 
fasttime::fastPOSIXct("2003-02-27")

# fast_strptime()
x <- "2001-02-27"
parse_date_time(x, order ="ymd")
fast_strptime(x, format = "%Y-%m-%d")
fast_strptime(x, format = "%y-%m-%d")

# Exporting datetimes
akl_hourly %>%
  select(datetime) %>%
  write_csv("data/tmp.csv")

```

### 4.3.2 Fast parsing with "fasttime"
```{r}
# Examine structure of dates
dates <- akl_hourly$datetime_string

# Examine structure of dates
str(dates)

# Use fastPOSIXct() to parse dates
fastPOSIXct(dates) %>% str()

# Compare speed of fastPOSIXct() to ymd_hms()
microbenchmark(
  ymd_hms = ymd_hms(dates), 
  fasttime = fastPOSIXct(dates), 
  times  = 20
)
```

It shows *fasttime* is about 20 times faster than *ymd_hms*. 

### 4.3.3 Fast parsing with *lubridate::fast_strptime*

```{r}
# head of dates
head(dates)

# parse dates with fast_strptime
fast_strptime(dates, format = "%Y-%m-%dT%H:%M:%S")

# Comparse speed to ymd_hms() and fasttime
microbenchmark(
  ymd_hms = ymd_hms(dates),
  fasttime = fastPOSIXct(dates),
  fast_strptime = fast_strptime(dates, 
    format = "%Y-%m-%dT%H:%M:%SZ"),
  times = 20)
```

### 4.3.4 Outputting pretty dates and times
```{r}
# Create a stamp based on "Sep 20 2017"
date_stamp <- stamp("Sep 20, 2017")

# Print date_stamp
date_stamp

# Call date_stamp on today()
date_stamp(today())

# Create and call a stamp based on "09/20/2017"
stamp("09/20/2017")(today())

# Use string finished for stamp()
finished <- "I finished 'Dates and Times in R' on Thursday, September 20, 2017!"
stamp(finished)(today())

?stamp

```

