---
title: "Working with Geospatial Data in R"
author: "Jeff Li"
date: "`r Sys.Date()`"
output: 
  html_document: 
    toc: true
    toc_depth: 3
    toc_float: true
---

"I maintained my edge by always being a student; you will always have something new to learn". - Jackie Joyner Kersee


Course Description: 

"Where should you buy a house to get the most value for your money? Your first step might be to make a map, but spatial analysis in R can be intimidating because of the complicated objects the data often live in.

This course will introduce you to spatial data by starting with objects you already know about, data frames, before introducing you to the special objects from the sp and raster packages used to represent spatial data for analysis in R. You'll learn to read, explore, and manipulate these objects with the big payoff of being able to use the tmap package to make maps.

By the end of the course you will have made maps of property sales in a small town, populations of the countries of the world, the distribution of people in the North East of the USA, and median income in the neighborhoods of New York City. "



Ref: Wickham, Charlotte. 2019. https://www.datacamp.com/.



Note: Some course materials have been adapted for my company training. 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(ggmap)

library(raster)
```


# 1. Basic mapping with ggplot2 and ggmap 

"We'll dive in by displaying some spatial data -- property sales in a small US town -- using ggplot2 and we'll introduce you to the ggmap package as a quick way to add spatial context to your plots. We'll talk about what makes spatial data special and introduce you to the common types of spatial data we'll be working with throughout the course."


## 1.1 Introduction to spatial data 

What is spatial data? 

* Data are associated with locations

* Locations described by coordinates + a coordinate reference system (CRS)

* common CRS: longitude, latitude describes locations on the surface of the Earth. 


Point data: 

locations are points, described by single pair of coordinates

### 1.1.1 Grabbing a background map 

There are two steps to add a map to a *ggplot2* plot with *ggmap*: 

* 1. Download a map using *get_map()*

* 2. Display the map using *ggmap()* 


*get_map()* has a number of arguments that control what kind of map to get. 

```{r}
# register a Google API
register_google(key = Sys.getenv("register_google_api")) 

visalia <- c(lon = -119.2921, lat = 36.3302 )

# get map at zoon level 5: map - 5
map_5 <- get_map(visalia, zoom = 5, scale = 1)

# plot map at zoom level 5
ggmap(map_5) 

# get map at zoom level 13: visalia_map

visalia_map <- get_map(visalia, zoom = 13, scale = 2)

# plot map at zoom level 13

ggmap(visalia_map)

```


```{r}
library(ggmap)

register_google(key = Sys.getenv("register_google_api")) 

ggmap(get_googlemap())


corvallis <- c(lon = -123.2620, lat = 44.5646)

# Get map at zoom level 5: map_5
map_5 <- get_map(corvallis, zoom = 5, scale = 1)

# Plot map at zoom level 5
ggmap(map_5)

# Get map at zoom level 13: corvallis_map
corvallis_map <- get_map(corvallis, zoom = 13, scale = 1)

# Plot map at zoom level 13
ggmap(corvallis_map)
```


## 1.2 Options of get_map() and ggmap()

* maptype = c("terrain", "terrain-background", "satellite", "roadmap", "hybrid", "toner", "watercolor", "toner-2010", .. )

* source = c("google"," "osm", "stamen")

Specifying default data and aesthetics: 

* ggmap(ggmap, exten = "panel", base_layer, maprange = FALSE, legend = "right", padding = 0.02, darken = c(0, "black"), ...)

* one option: base_layer = ggplot(xx, aes(x, y))

```{r}
corvallis <- c(lon = -123.2620, lat = 44.5646)

# Add a maptype argument to get a satellite map
corvallis_map_sat <- get_map(corvallis, maptype = "satellite",  zoom = 13)

# Edit to display satellite map
ggmap(corvallis_map_sat) +
  geom_point(aes(lon, lat, color = year_built), data = sales)

# Add source and maptype to get toner map from Stamen Maps
corvallis_map_bw <- get_map(corvallis, source = "stamen", maptype = "toner", zoom = 13)

# Edit to display toner map
ggmap(corvallis_map_bw) +
  geom_point(aes(lon, lat, color = year_built), data = sales)
```

## 1.3 Leveraging *ggplot2's* strengths

By moving aes(x, y) and data from the initial geom_point() function to the ggplot() call within the ggmap() call, you can add facets, or extra layers, the usual ggplot2 way.

```{r}
# use base_layer argument ot ggmap() to specifiy data and x, y mappings
ggmap(corvallis_map_bw, base_layer = ggplot(data = sales, aes(x = lon, y = lat))) +
  geom_point(aes(col = class)) +
  facet_wrap(~class)

```

Using a base layer saves you from having repeated code when you have several geoms.

## 1.4 qmplot()

```{r}
# Plot house sales using qmplot()
# qmplot(x = lon, y = lat, data = sales, geom = "point", color = bedrooms) + 
#   facet_wrap( ~ month)
```

## 1.5 Types of spatial data

* point

* line

* polygon

* raster (a.k.a Gridded)


## 1.6 Drawing polygons

```{r}
dir("data/")

ward_sales <- read_rds("data/01_corv_wards.rds")

head(ward_sales)

# Add a point layer with color mapped to ward
ggplot(ward_sales, aes(lon, lat)) +
  geom_point(aes(color = ward))


# Add a point layer with color mapped to group
ggplot(ward_sales, aes(lon, lat)) +
  geom_point(aes(color = group))


# Add a path layer with group mapped to group
ggplot(ward_sales, aes(lon, lat)) +
  geom_path(aes(group = group))


# Add a polygon layer with fill mapped to ward, and group to group
ggplot(ward_sales, aes(lon, lat)) +
  geom_polygon(aes(fill = ward, group = group))
```


## 1.7 Choropleth Map 

```{r}
# Fix the polygon cropping
ggmap(corvallis_map_bw,extent = "normal", maprange = FALSE, 
      base_layer = ggplot(ward_sales, aes(lon, lat))) +
  geom_polygon(aes(group = group, fill = ward))

# Repeat, but map fill to num_sales
ggmap(corvallis_map_bw,extent = "normal", maprange = FALSE, 
      base_layer = ggplot(ward_sales, aes(lon, lat))) +
  geom_polygon(aes(group = group, fill = num_sales))

# Repeat again, but map fill to avg_price
ggmap(corvallis_map_bw,extent = "normal", maprange = FALSE, 
      base_layer = ggplot(ward_sales, aes(lon, lat))) +
  geom_polygon(aes(group = group, fill = avg_price), alpha = 0.8)
```


## 1.8 Raster data as a heatmap


```{r}
# Predicted house prices iin preds are raster data
preds <- read_rds("data/01_corv_predicted_grid.rds")
head(preds)

# Add a geom_point() layer
ggplot(preds, aes(lon, lat)) +
  geom_point()

# Add a tile layer with fill mapped to predicted_price
ggplot(preds, aes(lon, lat)) +
  geom_tile(aes(fill = predicted_price))

# Use ggmap() instead of ggplot()
ggmap(corvallis_map_bw) +
  geom_tile(aes(lon, lat, fill = predicted_price), 
            data = preds, alpha = 0.8)
```



# 2. Introducing *sp* objects

Why do we need a new object - *sp*? 

Because Data frames aren't a great way to store spatial data: 

* Need an easy way to keep coordinate reference system information

* Inefficient for complicated spatial objects

* Hierarchical structure gets forced into a flat structure 


The *sp* package: 

* provides classes for storing different types of spatial data

* provides methods for spatial objects, for manipulation

* is useful for point, line and polygon data 

* is a standard, so new spatial packages expect data in an *sp* object 


## 2.1 A spatial object - take a look 

```{r}
library(sp)

countries_sp <- read_rds("data/02_countries_sp.rds")


# print(countries_sp)
class(countries_sp)


# Call summary() on countries_sp
summary(countries_sp)

# Call plot() on countries_sp
plot(countries_sp)
```


## 2.2 Waht's inside a spatial object? 

```{r}
# Call str() on countries_sp
#str(countries_sp)

# Call str() on countries_sp with max.level = 2
str(countries_sp, max.level = 2)
```


##  2.3 A more complicated spatial object

```{r}
# read data 
countries_spdf <- read_rds("data/02_countries_spdf.rds")

# Call summary() on countries_spdf and countries_sp
summary(countries_spdf)
summary(countries_sp)

# Call str() with max.level = 2 on countries_spdf
str(countries_spdf, max.level = 2)

# Plot countries_spdf
plot(countries_spdf)
```


## 2.4 Waling the hierarchy 

```{r}
# 169th element of countries_spdf@polygons: one
one <- countries_spdf@polygons[[169]]

# Print one
#one 

# Call summary() on one
summary(one)

# Call str() on one with max.level = 2
str(one, max.level = 2)


# str() with max.level = 2, on the Polygons slot of one
str(one@Polygons, max.level = 2)

# str() with max.level = 2, on the 6th element of the one@Polygons
str(one@Polygons[[6]])

# Call plot on the coords slot of 6th element of one@Polygons
plot(one@Polygons[[6]]@coords)


```


## 2.5 Subsetting by index

```{r}
# Subset the 169th object of countries_spdf: usa
usa <- countries_spdf[1, ]

# Look at summary() of usa
summary(usa)

# Look at str() of usa
str(usa, max.level = 2)

# Call plot() on usa
plot(usa)
```

## 2.6 Accessing data in sp objects 

```{r}
# Call head() and str() on the data slot of countries_spdf
head(countries_spdf@data)
str(countries_spdf@data)

# Pull out the name column using $
countries_spdf$name

# Pull out the subregion column using [[
countries_spdf[["subregion"]]
```


## 2.7 Subsetting based on data attributes

```{r}
# Create logical vector: is_nz
is_nz <- countries_spdf$name == "New Zealand"

# Subset countries_spdf using is_nz: nz
nz <- countries_spdf[is_nz, ]

# Plot nz
plot(nz)
```


## 2.7 tmap, a package that works with sp objects

```{r}
library(sp)
library(tmap)

# Use qtm() to create a choropleth map of gdp
qtm(shp = countries_spdf, fill = "gdp")

# Use qtm() to create a choropleth map of population
qtm(shp = countries_spdf, fill = "population")
```


## 2.8 Building a plot in layers

```{r}
# Add style argument to the tm_fill() call
tm_shape(countries_spdf) +
  tm_fill(col = "population", style = "quantile") +
    # Add a tm_borders() layer 
    tm_borders(col = "burlywood4")
  

# New plot, with tm_bubbles() instead of tm_fill()
tm_shape(countries_spdf) +
  tm_bubbles(size = "population", style = "quantile") +
    # Add a tm_borders() layer 
    tm_borders(col = "burlywood4")
```

## 2.9 Projection 

```{r}

# Switch to a Hoboâ€“Dyer projection , designed to preserve area.
tm_shape(countries_spdf, projection = "hd") +
  tm_grid(n.x = 11, n.y = 11) +
  tm_fill(col = "population", style = "quantile")  +
  tm_borders(col = "burlywood4") 

# Switch to a Robinson projection designed as a compromise between preserving local angles and area.
tm_shape(countries_spdf, projection = "robin") +
  tm_grid(n.x = 11, n.y = 11) +
  tm_fill(col = "population", style = "quantile")  +
  tm_borders(col = "burlywood4") 

# Add tm_style_classic() to your plot

tm_shape(countries_spdf, projection = "robin") +
  tm_grid(n.x = 11, n.y = 11) +
  tm_fill(col = "population", style = "quantile")  +
  tm_borders(col = "burlywood4") +
  tm_style_classic()

```


## 2.10 Save a tmap plot: static and interactive maps

```{r}

# Plot from last exercise
my_map <- tm_shape(countries_spdf) +
  tm_grid(n.x = 11, n.y = 11, projection = "longlat") +
  tm_fill(col = "population", style = "quantile")  +
  tm_borders(col = "burlywood4")

my_map

# Save a static version "population.png"
save_tmap(tm = my_map, filename = "population.png")

# Save an interactive version "population.html"
save_tmap(my_map, filename = "population.html")
```


# 3. Raster data and color

While the sp package provides some classes for raster data, the raster package provides more useful classes. You'll be introduced to these classes and their advantages and then learn to display them. The examples continue with the theme of population from Chapter 2, but you'll look at some much finer detail datasets, both spatially and demographically. In the second half of the chapter you'll learn about color -- an essential part of any visual display, but especially important for maps.


Data frames aren't a great way to store spatial data: 

* No CRS information

* Inefficient storage

* Inefficient display

A better structure for raster data: data matrix + information on grid + CRS


The *raster* package: 

* Easier import of rasters

* large rasters aren't read into memory

* provides functions for raster type operations

* Uses S4 and when appropriate provides same functions

## 3.1 What's a raster object? 

```{r}
data(pop)

# Print pop
pop

# Call str on pop, with max.level = 2
str(pop, max.level = 2)

# Call cummary on pop
summary(pop)


```


## 3.2 Some useful method

*pop* is a *RasterLayer* object, which contains the population around the Boston and NYC areas. Each grid cell simply contains a count of the number of people that live inside that cell.

You saw in the previous exercise that *print()* gives a useful summary of the object including the coordinate reference system, the size of the grid (both in number of rows and columns and geographical coordinates), and some basic info on the values stored in the grid. But it was very succinct; what if you want to see some of the values in the object?

The first way is to simply *plot()* the object. There is a *plot()* method for *raster* objects that creates a heatmap of the values.

If you want to extract the values from a *raster* object you can use the *values()* function, which pulls out a vector of the values. There are 316,800 values in the pop raster, so you won't want to print them all out, but you can use *str()* and *head()* to take a peek.

```{r}
# Call plot() on pop
plot(pop)

# Call str() on value(pop)
str(values(pop))

# call head
head(values(pop))
```

## 3.3 A more complicated object

The raster package provides the *RasterLayer* object, but also a couple of more complicated objects: *RasterStack* and *RasterBrick*. These two objects are designed for storing many rasters, all of the same extents and dimension (a.k.a. multi-band, or multi-layer rasters).

You can think of *RasterLayer* like a matrix, but *RasterStack* and *RasterBrick* objects are more like three dimensional arrays. One additional thing you need to know to handle them is how to specify a particular layer.

You can use *$* or *[[* subsetting on a RasterStack or RasterBrick to grab one layer and return a new RasterLayer object. For example, if x is a RasterStack, *x$layer_name* or x[["layer_name"]] will return a RasterLayer with only the layer called layer_name in it.

Let's look at a RasterStack object called pop_by_age that covers the same area as pop but now contains layers for population broken into few different age groups.

```{r}
data("pop_by_age")

# print pop_by_age
pop_by_age

# Subset out the under_1 layer using [[
pop_by_age[["under_1"]]

# Plot the under_1 layer
plot(pop_by_age[["under_1"]])
```

## 3.4 A package that uses Raster objects

You saw the tmap package makes visualizing spatial classes in sp easy. The good news is that it works with the raster classes too! You simply pass your Raster___ object as the shp argument to the tm_shape() function, and then add a tm_raster() layer like this:

tm_shape(raster_object) +
    tm_raster()
When working with a RasterStack or a RasterBrick object, such as the pop_by_age object you created in the last exercise, you can display one of its layers using the col (short for "color") argument in tm_raster(), surrounding the layer name in quotes.

You'll work with tmap throughout the course, but we also want to show you another package, rasterVis, also designed specifically for visualizing raster objects. There are a few different functions you can use in rasterVis to make plots, but let's just try one of them for now: levelplot().

```{r}
library(tmap)

# Specify pop as the shp and add a tm_raster() layer
tm_shape(pop) +
  tm_raster()

# Plot the under_1 layer in pop_by_age
tm_shape(pop_by_age) +
tm_raster(col = "under_1" )


library(rasterVis)
# Call levelplot() on pop
levelplot(pop)
```

None of these plots are very informative, because the color scales aren't great. 


## 3.5 Picking the right palette and Adding a custom continuous color palette to ggplot2 plots

The most versatile way to add a custom continuous scale to ggplot2 plots is with scale_color_gradientn() or scale_fill_gradientn(). How do you know which to use? Match the function to the aesthetic you have mapped. For example, in your plot of predicted house price from Chapter 1, you mapped fill to price, so you'd need to use scale_fill_gradientn().

These two functions take an argument colors where you pass a vector of colors that defines your palette. This is where the versatility comes in. You can generate your palette in any way you choose, automatically using something like RColorBrewer or viridisLite, or manually by specifying colors by name or hex code.

The scale___gradientn() functions handle how these colors are mapped to values of your variable, although there is control available through the values argument.

```{r}
library(RColorBrewer)

# 9 steps on the RColorBrewer "BuPu" palette: blups

blups <- RColorBrewer::brewer.pal(n = 9, name = "BuPu")

# Add scale_fill_gradientn() with the blups palette
data(preds)

ggplot(preds) +
  geom_tile(aes(lon, lat, fill = predicted_price), alpha = 0.8) +
  scale_fill_gradientn(colors = blups)



library(viridisLite)
# viridisLite viridis palette with 9 steps: vir
vir <- viridis(n = 9)

# Add scale_fill_gradientn() with the vir palette
ggplot(preds) +
  geom_tile(aes(lon, lat, fill = predicted_price), alpha = 0.8)  +
  scale_fill_gradientn(colors = vir)


# mag: a viridisLite magma palette with 9 steps
mag <- magma(n = 9)

# Add scale_fill_gradientn() with the mag palette
ggplot(preds) +
  geom_tile(aes(lon, lat, fill = predicted_price), alpha = 0.8) +
  scale_fill_gradientn(colors = mag)
```

Great work! If you know you want a RColorBrewer palette, there is a shortcut. Add scale_xxx_distiller and you only need to specify the palette name in the palette argument. See ?scale_fill_distiller


## 3.6 Custom palette in tmap

Unlike *ggplot2*, where setting a custom color scale happens in a *scale_* call, colors in *tmap* layers are specified in the layer in which they are mapped. For example, take a plot of the age_18_24 variable from prop_by_age:

*tm_shape(prop_by_age) +*
  *tm_raster(col = "age_18_24")* 
  
Since color is mapped in the *tm_raster()* call, the specification of the palette also occurs in this call. You simply specify a vector of colors in the palette argument. This is a another reason it's worth learning ways to generate a vector of colors. While different packages could have very different shortcuts for specifying palettes from color packages, they will generally always have a way to pass in a vector of colors.

```{r}
# Generate palettes from last time
library(RColorBrewer)
blups <- brewer.pal(9, "BuPu")

library(viridisLite)
vir <- viridis(9)
mag <- magma(9)

# Use the blups palette
data(prop_by_age)

tm_shape(prop_by_age) +
  tm_raster("age_18_24", palette = blups) +
  tm_legend(position = c("right", "bottom"))

# Use the vir palette
tm_shape(prop_by_age) +
  tm_raster("age_18_24", palette = vir) +
  tm_legend(position = c("right", "bottom"))

# Use the mag palette but reverse the order
tm_shape(prop_by_age) +
  tm_raster("age_18_24", palette = rev(mag)) +
  tm_legend(position = c("right", "bottom"))
```


## 3.7 An interval scale example


Let's return to your plot of the proportion of the population that is between 18 and 24:

tm_shape(prop_by_age) +
  tm_raster("age_18_24", palette = vir) +
  tm_legend(position = c("right", "bottom"))
  
Your plot was problematic because most of the proportions fell in the lowest color level and consequently you didn't see much detail in your plot. One way to solve this problem is this: instead of breaking the range of your variable into equal length bins, you can break it into more useful categories.

Let's start by replicating the tmap default bins: five categories, cut using "pretty" breaks. Then you can try out a few of the other methods to cut a variable into intervals. Using the classIntervals() function directly gives you quick feedback on what the breaks will be, but the best way to try out a set of breaks is to plot them.

(As an aside, another way to solve this kind of problem is to look for a transform of the variable so that equal length bins of the transformed scale are more useful.)


```{r}
mag <- viridisLite::magma(7)

library(classInt)

# Create 5 "pretty" breaks with classIntervals()
classIntervals(values(prop_by_age[["age_18_24"]]), n = 5, style = "pretty")


# Create 5 "quantile" breaks with classIntervals()
classIntervals(values(prop_by_age[["age_18_24"]]), n = 5, style = "quantile")


# Use 5 "quantile" breaks in tm_raster()
tm_shape(prop_by_age) +
  tm_raster("age_18_24", palette = mag, n = 5, style = "quantile") +
  tm_legend(position = c("right", "bottom"))

# Create histogram of proportions
hist(values(prop_by_age[["age_18_24"]]))

# Use fixed breaks in tm_raster()
tm_shape(prop_by_age) +
  tm_raster("age_18_24", palette = mag,
    style = "fixed", breaks = c(0.025, 0.05, 0.1, 0.2, 0.25, 0.3, 1))

# Save your plot to "prop_18-24.html"
save_tmap(filename = "prop_18-24.html")
```

## 3.8 A diverging scale example

Let's take a look at another dataset where the default color scale isn't appropriate. This raster, migration, has an estimate of the net number of people who have moved into each cell of the raster between the years of 1990 and 2000. A positive number indicates a net immigration, and a negative number an emigration. Take a look:

tm_shape(migration) +
  tm_raster() +
  tm_legend(outside = TRUE, 
            outside.position = c("bottom"))
The default color scale doesn't look very helpful, but tmap is actually doing something quite clever: it has automatically chosen a diverging color scale. A diverging scale is appropriate since large movements of people are large positive numbers or large (in magnitude) negative numbers. Zero (i.e. no net migration) is a natural midpoint.

tmap chooses a diverging scale when there are both positive and negative values in the mapped variable and chooses zero as the midpoint. This isn't always the right approach. Imagine you are mapping a relative change as percentages; 100% might be the most intuitive midpoint. If you need something different, the best way to proceed is to generate a diverging palette (with an odd number of steps, so there is a middle color) and specify the breaks yourself.

```{r}
# print migration  to verify this is a RasterLayer object and take a look at the range in migration values.
data("migration")
migration

# Diverging "RdGy" pallette
red_gray <- brewer.pal(n = 7, name = "RdGy")


# Use red_gray as the palette 
tm_shape(migration) +
  tm_raster(palette = red_gray) +
  tm_legend(outside = TRUE, outside.position = c("bottom"))

# Add fixed breaks 
tm_shape(migration) +
  tm_raster(palette = red_gray, style = "fixed", breaks = c(-5e6, -5e3, -5e2, -5e1, 5e1, 5e2, 5e3, 5e6)) +
  tm_legend(outside = TRUE, outside.position = c("bottom"))

```

## 3.9 A qualitative example 

Finally, let's look at an example of a categorical variable. The land_cover raster contains a gridded categorization of the earth's surface. Have a look at land_cover by printing it:

land_cover
You will notice that the values are numeric, but there are attributes that map these numbers to categories (just like the way factors work).

Choosing colors for categorical variables depends a lot on the purpose of the graphic. When you want the categories to have roughly equal visual weight -- that is, you don't want one category to stand out more than the others -- one approach is to use colors of varying hues, but equal chroma (a measure of vibrancy) and lightness (this is default for discrete color scales in ggplot2 and can be generated using the hcl() function).

The RColorBrewer qualitative palettes balance having equal visual weight colors with ease of color identification. The "paired" and "accent" schemes deviate from this by providing pairs of colors of different lightness and a palette with some more intense colors that may be used to highlight certain categories, respectively.

For this particular data, it might make more sense to choose intuitive colors, like green for forest and blue for water. Whichever is more appropriate, setting new colors is just a matter of passing in a vector of colors through the palette argument in the corresponding tm_*** layer.


```{r}
library(raster)

# Plot land_cover
data("land_cover")

tm_shape(land_cover) + 
  tm_raster()


# Palette like the ggplot2 default
hcl_cols <- hcl(h = seq(15, 375, length = 9),
                c = 100, l = 65)[-9]

# Use hcl_cols as the palette
tm_shape(land_cover) +
  tm_raster(palette = hcl_cols)


# Examine levels of land_cover
levels(land_cover)

# A set of intuitive colors
intuitive_cols <- c(
  "darkgreen",
  "darkolivegreen4",
  "goldenrod2",
  "seagreen",
  "wheat",
  "slategrey",
  "white",
  "lightskyblue1"
)

# Use intuitive_cols as palette
tm_shape(land_cover) +
  tm_raster(palette = intuitive_cols) + 
  tm_legend(position = c("left", "bottom"))


```



# 4. Data Import and Projections 

In this chapter you'll follow the creation of a visualization from raw spatial data files to adding a credit to a map. Along the way, you'll learn how to read spatial data into R, more about projections and coordinate reference systems, how to add additional data to a spatial object, and some tips for polishing your maps.

## 4.1 Reading in a shapefile 

*Shapefiles* are one of the most common ways spatial data are shared and are easily read into R using *readOGR()* from the *rgdal* package. *readOGR()* has two important arguments: *dsn* and *layer*. Exactly what you pass to these arguments depends on what kind of data you are reading in. You learned in the video that for shapefiles, dsn should be the path to the directory that holds the files that make up the shapefile and layer is the file name of the particular shapefile (without any extension).

For your map, you want neighborhood boundaries. We downloaded the Neighborhood Tabulation Areas, as defined by the City of New York, from the Open Data Platform of the Department of City Planning. The download was in the form of a zip archive and we have put the result of unzipping the downloaded file in your working directory.

You'll use the dir() function from base R to examine the contents of your working directory, then read in the shapefile to R.

```{r}
library(sp)
library(rgdal)
library(sf)

# Use dir() to find directory name
dir()

# Call dir() with directory name
dir("data/nynta_19a")

# Read in shapefile with readOGR(): neighborhoods
neighborhoods <- readOGR("data/nynta_19a", "nynta")

# using the package of sf
neighborhoods_2 <- sf::st_read("data/nynta_19a/nynta.shp")


# summary() of neighborhoods
summary(neighborhoods)
summary(neighborhoods_2)

# Plot neighboorhoods
plot(neighborhoods)
# Plot the same data imported using sf::st_read
plot(neighborhoods_2)

# Plot just the geometry of big_parks
plot(st_geometry(neighborhoods_2))
```

## 4.2 Reading in a raster file

Raster files are most easily read in to R with the *raster()* function from the *raster* package. You simply pass in the filename (including the extension) of the raster as the first argument, x.

The *raster()* function uses some native raster package functions for reading in certain file types (based on the extension in the file name) and otherwise hands the reading of the file on to *readGDAL()* from the *rgdal* package. The benefit of not using *readGDAL()* directly is simply that *raster()* returns a RasterLayer object.

A common kind of raster file is the GeoTIFF, with file extension .tif or .tiff. 

```{r}
library(raster) 

# Call dir()
dir("data")

# Use raster() with file path: income_grid
income_grid <- raster::raster("data/m5602ahhi00.tif")

# Call summary() on income_grid
summary(income_grid)

# Call plot() on income_grid
plot(income_grid)
```

## 4.3 Getting data using a package

Reading in spatial data from a file is one way to get spatial data into R, but there are also some packages that provide commonly used spatial data. For example, the *rnaturalearth* package provides data from Natural Earth, a source of high resolution world maps including coastlines, states, and populated places. In fact, this was the source of the data from Chapter 2.

You will be examining median income at the census tract level in New York County (a.k.a. the Bourough of Manhattan), but to do this you'll need to know the boundaries of the census tracts. The *tigris* package in R provides a way to easily download and import shapefiles based on US Census geographies. You'll use the *tracts()* function to download tract boundaries, but *tigris* also provides *states()*, *counties()*, *places()* and many other functions that match the various levels of geographic entities defined by the Census.

Let's grab the spatial data for the tracts.

```{r}
library(sp)
library(tigris)

# Call tracts(): nyc_tracts
nyc_tracts <- tracts(state = "NY", county = "New York", cb = TRUE)

alameda_tracts <- tracts(state = "CA", county = "Alameda", cb = TRUE)

# Call summary() on nyc_tracts
summary(nyc_tracts)

# Plot nyc_tracts
plot(nyc_tracts)

# Plot Alameda County, CA
plot(alameda_tracts)
```

In case you were wondering, the final argument cb = TRUE downloads the lower resolution boundaries which makes for a quicker download.


## 4.4 Merging data from different CRS/projections

Every spatial object has a coordinate reference system (CRS) associated with it. Generally, this is set when the data are imported and will be read directly from the spatial files. This is how the *neighborhoods* and *nyc_tracts* obtained their coordinate system information.

Both the *sp* and *raster* packages have a *proj4string()* function that returns the CRS of the object it's called on.

Trying to work with spatial data using different CRSs is a bit like trying to work with a dataset in miles and another in kilometers. They are measuring the same thing, but the numbers aren't directly comparable.

```{r}
library(sp)

# proj4string() on nyc_tracts and neighborhoods
proj4string(nyc_tracts)
proj4string(neighborhoods)


# coordinates() on nyc_tracts and neighborhoods
head(coordinates(nyc_tracts))
head(coordinates(neighborhoods))


# plot() neighborhoods and nyc_tracts
plot(neighborhoods)
plot(nyc_tracts, col = "red", add = TRUE)

```
Why didn't we see the tracts on our plot of neighborhoods? Simply because the coordinates of the tracts put them way off the boundaries of our plot.


## 4.5 Converting from one CRS/projection to another

The process of converting from one CRS or projection to another is handled by the *spTransform()* methods in the *rgdal* package. *spTransform()* has methods for all *sp* objects including *SpatialPolygonsDataFrame*, but doesn't work on *raster* objects. This is because transforming a *raster* is a little more complicated; the transformed rectangular grid will no longer be rectangular. You can look at *?raster::projectRaster* if you are curious about transforming rasters.

Transformation is simple. The first argument to *spTransform()*, x, is the spatial object to be transformed and the second, CRS, is a specification of the desired *CRS*. The CRS can be specified by a PROJ4 string, which you could construct by hand, but it's much easier to take it from an existing object (e.g. with the *proj4string()* function).

Time to get your two polygons datasets into the same CRS.

```{r}
library(sp)
library(raster)

# Use spTransform on neighborhoods: neighborhoods
spTransform(neighborhoods, proj4string(nyc_tracts))


# head() on coordinates() of neighborhoods
head(neighborhoods)
coordinates(neighborhoods)

data(water)

# Plot neighborhoods, nyc_tracts and water
plot(neighborhoods)
plot(nyc_tracts, add = TRUE, col = "red")
plot(water, add = TRUE, col = "blue")
```

## 4.6 The wrong way

When a *Spatial***DataFrame* object is created, there are two ways the spatial objects (e.g. Polygons) might be matched up to the rows of the data. The most robust is to use IDs on the spatial objects that are matched up to row names in the data. This ensures if there are any that don't match you are quickly alerted. The other way is simply by order -- the first spatial object is assumed to correspond to the first row of data.

Once created, the correspondence is based purely on order. If you manipulate the data slot, there is no checking the spatial objects still correspond to the right rows. What does this mean in practice? It's very dangerous to manipulate the data slot directly!

To create your plot of income, you need to match up the income data frame with the tracts SpatialPolygonsDataFrame. To illustrate the danger of manipulating @data directly, let's see what happens if you try to force nyc_income in to nyc_tracts.


```{r}
library(sp)

# Use str() on nyc_income 
data("nyc_income")
str(nyc_income)

# ...and on nyc_tracts@data
nyc_tracts <- tigris::tracts(state = "NY", county = "New York", cb = TRUE)

str(nyc_tracts@data)

# Highlight tract 002201 in nyc_tracts
plot(nyc_tracts)
plot(nyc_tracts[nyc_tracts$TRACTCE == "002201", ], 
     col = "red", add = TRUE)
     
# Set nyc_tracts@data to nyc_income
nyc_tracts@data <- nyc_income

# Highlight tract 002201 again
plot(nyc_tracts)
plot(nyc_tracts[nyc_tracts$tract == "002201", ], 
     col = "red", add = TRUE)

```

## 4.7 Checking data will match
Forcing your data into the data slot doesn't work because you lose the correct correspondence between rows and spatial objects. How do you add the income data to the polygon data? The merge() function in sp is designed exactly for this purpose.

You might have seen merge() before with data frames. sp::merge() has almost the exact same structure, but you pass it a Spatial*** object and a data frame and it returns a new Spatial*** object where the data slot is now a merge of the original data slot and the data frame. To do this merge, you'll require both the spatial object and data frame to have a column that contains IDs to match on.

Both nyc_tracts and nyc_income have columns with tract IDs, so these are great candidates for merging the two datasets. However, it's always a good idea to check that the proposed IDs are unique and that there is a match for every row in both datasets.

```{r}

# Check for duplicates in nyc_income
any(duplicated(nyc_income$tract))

# Check for duplicates in nyc_tracts
any(duplicated(nyc_tracts$TRACTCE))

# Check nyc_tracts in nyc_income
all(nyc_tracts$TRACTCE %in% nyc_income$tract)

# Check nyc_income in nyc_tracts
all(nyc_income$tract %in% nyc_tracts$TRACTCE)

```

Looks like the tract column in nyc_income and the TRACTCE column in nyc_income are ideal for merging on.

## 4.8 Merging data attributes

```{r}
library(sp)
library(tmap)

# Merge nyc_tracts and nyc_income: nyc_tracts_merge
nyc_tracts_merge <- merge(nyc_tracts, nyc_income, by.x = "TRACTCE", by.y = "tract")

# Call summary() on nyc_tracts_merge
summary(nyc_tracts_merge)

# Choropleth with col mapped to estimate
tm_shape(shp = nyc_tracts_merge) +
  tm_fill( col = 'estimate')
```

## 4.9 A first plot

So far, you've read in some spatial files, transformed spatial data to the same projection, and merged a data frame with a spatial object. Time to put your work together and see how your map looks. For each dataset, you need a tm_shape() call to specify the data source, followed by a tm_* layer (like tm_fill(), tm_borders() or tm_bubbles()) to draw on the map.

First, you'll add the neighborhoods and water areas to your plot from the previous exercise.

```{r}
data("water")
data('neighborhoods')

library(tmap)

tm_shape(nyc_tracts_merge) +
  tm_fill(col = "estimate") +
  # Add a water layer, tm_fill() with col = "grey90"
  tm_shape(water) +
  tm_fill(col = "grey90") +
  #Add a neighborhood layer, tm_borders()
  tm_shape(neighborhoods) +
  tm_borders()
```

## 4.10 Subsetting the neighborhoods

You don't need all those extraneous neighborhoods in New York, so you'll subset out just the neighborhoods in New York County. You already know how!

neighborhoods is a SpatialPolygonsDataFrame and you learned back in Chapter 2 how to subset based on the column in the data slot. The key was creating a logical vector, then subsetting the SpatialPolygonsDataFrame like a data frame.

How can you identify the right neighborhoods? Check out:

head(neighborhoods@data)
The CountyFIPS is a numeric code that identifies the county. If you can figure out the code for New York County, you can keep just the rows with that value.


```{r}
library(tmap)

# Find unique() nyc_tracts_merge$COUNTYFP
unique(nyc_tracts_merge$COUNTYFP)

# Add logical expression to pull out New York County
head(neighborhoods@data)
manhat_hoods <- neighborhoods[neighborhoods$CountyFIPS == "061", ]

tm_shape(nyc_tracts_merge) +
  tm_fill(col = "estimate") +
  tm_shape(water) +
  tm_fill(col = "grey90") +
  # Edit to use manhat_hoods instead
  tm_shape(manhat_hoods) +
  tm_borders() +
  # Add a tm_text() layer
  tm_text("NTAName")
  
    
```

## 4.11 Adding neighborhood labels

The neighborhood labels are so long and big they are obscuring our data. Take a look at manhat_hoods$NTAName. You'll see some neighborhoods are really the combination of a couple of places. One option to make the names a little more concise is to split them into a few lines. For example, turning

Midtown-Midtown South
into

Midtown /
Midtown 
South

To do this, you can make use of the gsub() function in base R. gsub() replaces the first argument by the second argument in the strings provided in the third argument. For example, gsub("a", "A", x) replaces all the "a"s in x with "A".

You also might play with the size of the text to shrink the impact of the neighborhood names.

```{r}
library(tmap)

# gsub() to replace " " with "\n"
manhat_hoods$name <- gsub(" ", "\n", manhat_hoods$NTAName)

# gsub() to replace "-" with "/\n"
manhat_hoods$name <- gsub("-", "/\n", manhat_hoods$name)

# Edit to map text to name, set size to 0.5
tm_shape(nyc_tracts_merge) +
    tm_fill(col = "estimate") +
  tm_shape(water) +
    tm_fill(col = "grey90") +
  tm_shape(manhat_hoods) +
    tm_borders() +
    tm_text(text = "name", size = 0.5)
```

## 4.12 Tidying up the legend and some final tweaks

Time for some final tweaks and then to save your plot.

Every element in your plot is a target for tweaks. Is it the right color? Is it the right size? Does it have intuitive labels? Your goal is to emphasize the data and de-emphasise the non-data elements.

We've got some ideas for this plot. Let's tweak a few things.



```{r}
library(tmap)

tm_shape(nyc_tracts_merge) +
  # Add title and change palette
  tm_fill(col = "estimate", 
          title = "Median Income",
          palette = "Greens") +
  # Add tm_borders()
  tm_borders(col = "grey60", lwd = 0.5) +
  tm_shape(water) +
  tm_fill(col = "grey90") +
  tm_shape(manhat_hoods) +
  # Change col and lwd of neighborhood boundaries
  tm_borders(col = "grey40", lwd = 2) +
  tm_text(text = "name", size = 0.5) +
  # Add tm_credits()
  tm_credits("Source: ACS 2014 5-year Estimates, \n accessed via acs package", position = c("right", "bottom"))
  
        
# Save map as "nyc_income_map.png"
tmap_save(filename = "nyc_income_map.png", width = 4, height = 7)
```

