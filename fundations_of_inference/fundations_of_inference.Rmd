---
title: "Foundations of Inference"
author: "Jeff Li"
date: "`r Sys.Date()`"
output: 
  html_document: 
    toc: true
    toc_depth: 3
    toc_float: true
---



**Course Description**

"One of the foundational aspects of statistical analysis is inference, or the process of drawing conclusions about a larger population from a sample of data. Although counter intuitive, the standard practice is to attempt to disprove a research claim that is not of interest. For example, to show that one medical treatment is better than another, we can assume that the two treatments lead to equal survival rates only to then be disproved by the data. Additionally, we introduce the idea of a p-value, or the degree of disagreement between the data and the hypothesis. We also dive into confidence intervals, which measure the magnitude of the effect of interest (e.g. how much better one treatment is than another)." 



Ref: Hardin, Jo. (2019) "Foundations of Inference". https://www.datacamp.com/courses


Note: Some course materials and data have been digested and adapted for my teaching. 



# (I) Load Required Libraries

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# (b) Load libraries
library(tidyverse)
library(NHANES)
library(infer)
```

# 1. Introduction to ideas of inference 

In this chapter, Prof. Hardin introduced how repeated samples taken from a population can vary. It is the variability in samples that allow us to make claims about the population of interest. It is important to remember that the research claims of interest focus on the population while the information available comes only from the sample data. 

## 1.1 What is statistical inference?

The process of making claims about a population based on information from a sample. 

Null hypothesis (Ho): the claim that is not interesting
Alternative hypothesis (Ha): The claim corresponding to the research hypothesis. 

The "goal" is to disprove the null hypothesis. 

### 1.1.1 Working with the NHANES data

We will use the *NHANES* dataset from the *NHANES* R package. The data are collected by the Center for Disease Control. 

```{r}
# structure of data
str(NHANES)
names(NHANES)

# Create bar plot for Home Ownership by Gender
ggplot(data = NHANES, aes(x = Gender, fill = HomeOwn)) +
  geom_bar(position = "fill") +
  ylab("Relative frequencies")

# Density plot of SleepHrsNight colored by SleepTroubles
ggplot(data = NHANES, aes(x = SleepHrsNight, color = SleepTrouble)) +
  geom_density(adjust = 2) + 
  facet_wrap(~ HealthGen)
```


### 1.1.2 Calculating statistic of interest

```{r}
# select data 
homes <- NHANES %>%
  select(Gender, HomeOwn) %>%
  filter(HomeOwn %in% c("Own", "Rent"))

# Find the observed difference in proportions of men who own and women who own
diff_orig <- homes %>%
  group_by(Gender) %>%
  summarize(prop_own = mean(HomeOwn == "Own")) %>%
  summarize(obs_diff_prop = diff(prop_own))


```

### 1.1.3 Randomized data under null model of independence

The *infer* package will allow you to model a particular null hypothesis and then randomized the data to calculate permuted statistics. In this exercise, after specifying the null hypothesis we will permute the home ownership variable 10 times. By doing so, we will ensure that there is no relationship between home ownership and gender, so any difference in home ownership proportion for female versus male will be due only to natural variability. 


```{r}
# Specify variables
homeown_perm <- homes %>%
  specify(HomeOwn ~ Gender, success = "Own") %>%
  # gender and homeown are not related
  hypothesize(null = "independence")   %>%
  # generate resamples/permutations/simulations
  generate(reps = 10, type = "permute")

```

* (1) Defined the response and explanatory variables

* (2) Set the independence null hypothesis 

* (3) Shuffled the response variable, *HomeOwn*, ten times. 


### 1.1.4 Randomized statistics and dotplot

By permuting the home ownership variable multiple times, you generate differences in proportions that are consistent with the assumption that the variables are unrelated. The statistic of interest is the difference in proportions given by stat = "diff in props". After calculating the randomized statistics, you will plot them in a dotplot.

```{r}
# Perform 100 permutations
homeown_perm <- homes %>%
  specify(HomeOwn ~ Gender, success = "Own") %>%
  hypothesize(null = "independence") %>%
  generate(reps = 100, type = "permute") %>%
  calculate(stat = "diff in props", order = c("male", "female"))

# Dotpot of 100 permuted differences in proportions
ggplot(homeown_perm, aes(x = stat)) + 
  geom_dotplot(binwidth = 0.001)
```


### 1.1.5 Randomization density 

```{r}
# Perform 1000 permutations
homeown_perm <- homes %>%
  # Specify HomeOwn vs. Gender, with `"Own" as success
  specify(HomeOwn ~ Gender, success = "Own") %>%
  # Use a null hypothesis of independence
  hypothesize(null = "independence") %>% 
  # Generate 1000 repetitions (by permutation)
  generate(reps = 1000, type = "permute") %>% 
  # Calculate the difference in proportions (male then female)
  calculate(stat = "diff in props", order = c("male", "female"))

# Density plot of 1000 permuted differences in proportions
ggplot(homeown_perm, aes(x = stat)) + 
  geom_density()
```

As shown in the plot, the "diff in prop" is approximately normally distributed around -0.01. 


## 1.2 Using the randomization distribution 
```{r}

# Plot permuted differences, diff_perm
ggplot(homeown_perm, aes(x = stat)) + 
  # Add a density layer
  geom_density() +
  # Add a vline layer with intercept diff_orig
  geom_vline(aes(xintercept = diff_orig$obs_diff_prop), color = "red")

# Compare permuted differences to observed difference
homeown_perm %>%
  summarize(n_perm_le_obs = sum(stat <= diff_orig$obs_diff_prop))
```

Only 197 permuted differences are more extreme than the observed difference. This only represents 19.7% of the null statistics, so we can conclude that the observed difference is consistent with permuted distribution. 

